{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "LOAD IMAGES GRADUALLY AS YOU TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: datasets/kutaykutlu_forest-fire/train-smoke: No such file or directory\n",
      "rm: datasets/kutaykutlu_forest-fire/test_small: No such file or directory\n",
      "rm: datasets/kutaykutlu_forest-fire/test_big: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm datasets/kutaykutlu_forest-fire/train-smoke/ -r\n",
    "!rm datasets/kutaykutlu_forest-fire/test_small/ -r\n",
    "!rm datasets/kutaykutlu_forest-fire/test_big/ -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make things simpler, the datasets will be renamed: <br>\n",
    "alik05_forest-fire-dataset = dataset1 <br> <br>\n",
    "elmadafri_the-wildfire-dataset = dataset2 <br> <br>\n",
    "kutaykutlu_forest-fire = dataset3 <br> <br>\n",
    "mohnishsaiprasad_forest-fire-images = dataset4 <br> <br>\n",
    "phylake1337_fire-dataset = dataset5 <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_path = \"datasets/alik05_forest-fire-dataset/Forest Fire Dataset/\"\n",
    "dataset2_path = \"datasets/elmadafri_the-wildfire-dataset/the_wildfire_dataset_2n_version/\"\n",
    "dataset3_path = \"datasets/kutaykutlu_forest-fire/\"\n",
    "dataset4_path = \"datasets/mohnishsaiprasad_forest-fire-images/Data/\"\n",
    "dataset5_path = \"datasets/phylake1337_fire-dataset/fire_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_paths(dataset_path,folders_labels):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    for folder,label in folders_labels:\n",
    "        try:\n",
    "            for f in os.scandir(dataset_path+folder):\n",
    "                if f.is_file() and f.name.endswith((\".jpg\", \".png\")):\n",
    "                    dataset_x.append(dataset_path+folder+f.name)\n",
    "                    dataset_y.append(label)\n",
    "        except:\n",
    "            break                \n",
    "    return dataset_x,dataset_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 1900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1_X, dataset1_Y = load_data_paths(dataset1_path,[(\"Training/fire\",1),(\"Training/nofire\",0)])\n",
    "\n",
    "for f in os.scandir(dataset1_path+\"Testing\"):\n",
    "    if f.is_file() and f.name.endswith((\".jpg\", \".png\")):\n",
    "        dataset1_X.append(dataset1_path+\"Testing/\"+f.name)\n",
    "        dataset1_Y.append(0 if f.name.split(\"_\")[0] == \"nofire\" else 1)\n",
    "        \n",
    "len(dataset1_X),len(dataset1_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2699, 2699)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_X, dataset2_Y = load_data_paths(dataset2_path,[(\"test/fire\",1),(\"test/nofire\",0),(\"train/fire\",1),(\"train/nofire\",0),(\"val/fire\",1),(\"val/nofire\",0)])\n",
    "\n",
    "len(dataset2_X),len(dataset2_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102, 1102)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3_X, dataset3_Y = load_data_paths(dataset3_path,[(\"train_fire\",1)])\n",
    "\n",
    "len(dataset3_X),len(dataset3_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5049, 5049)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4_X, dataset4_Y = load_data_paths(dataset4_path,[(\"Test_Data/Fire\",1),(\"Test_Data/Non_Fire\",0),(\"Train_Data/Fire\",1),(\"Train_Data/Non_Fire\",0)])\n",
    "\n",
    "len(dataset4_X),len(dataset4_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 999)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset5_X, dataset5_Y = load_data_paths(dataset5_path,[(\"fire_images\",1),(\"non_fire_images\",0)])\n",
    "\n",
    "len(dataset5_X),len(dataset5_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset1_X = np.array(dataset1_X)\n",
    "dataset1_Y = np.array(dataset1_Y)\n",
    "dataset3_X = np.array(dataset3_X)\n",
    "dataset3_Y = np.array(dataset3_Y)\n",
    "dataset4_X = np.array(dataset4_X)\n",
    "dataset4_Y = np.array(dataset4_Y)\n",
    "dataset5_X = np.array(dataset5_X)\n",
    "dataset5_Y = np.array(dataset5_Y)\n",
    "\n",
    "X_train_dataset1,X_test_dataset1,Y_train_dataset1,Y_test_dataset1 = train_test_split(dataset1_X,dataset1_Y,test_size=0.16)\n",
    "X_train_dataset1,X_test_dataset1,Y_val_dataset1,Y_val_dataset1 = train_test_split(X_train_dataset1,Y_train_dataset1,test_size=0.19)\n",
    "\n",
    "X_train_dataset2,X_test_dataset2,Y_train_dataset2,Y_test_dataset2 = train_test_split(dataset2_X,dataset2_Y,test_size=0.16)\n",
    "X_train_dataset2,X_test_dataset2,Y_val_dataset2,Y_val_dataset2 = train_test_split(X_train_dataset2,Y_train_dataset2,test_size=0.19)\n",
    "\n",
    "X_train_dataset3,X_test_dataset3,Y_train_dataset3,Y_test_dataset3 = train_test_split(dataset3_X,dataset3_Y,test_size=0.16)\n",
    "X_train_dataset3,X_test_dataset3,Y_val_dataset3,Y_val_dataset3 = train_test_split(X_train_dataset3,Y_train_dataset3,test_size=0.19)\n",
    "\n",
    "X_train_dataset4,X_test_dataset4,Y_train_dataset4,Y_test_dataset4 = train_test_split(dataset4_X,dataset4_Y,test_size=0.16)\n",
    "X_train_dataset4,X_test_dataset4,Y_val_dataset4,Y_val_dataset4 = train_test_split(X_train_dataset4,Y_train_dataset4,test_size=0.19)\n",
    "\n",
    "X_train_dataset5,X_test_dataset5,Y_train_dataset5,Y_test_dataset5 = train_test_split(dataset5_X,dataset5_Y,test_size=0.16)\n",
    "X_train_dataset5,X_test_dataset5,Y_val_dataset5,Y_val_dataset5 = train_test_split(X_train_dataset5,Y_train_dataset5,test_size=0.19)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "second_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
