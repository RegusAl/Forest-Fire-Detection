{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "LOAD IMAGES GRADUALLY AS YOU TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: raw_datasets/kutaykutlu_forest-fire/train-smoke: No such file or directory\n",
      "rm: raw_datasets/kutaykutlu_forest-fire/test_small: No such file or directory\n",
      "rm: raw_datasets/kutaykutlu_forest-fire/test_big: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm raw_datasets/kutaykutlu_forest-fire/train-smoke/ -r\n",
    "!rm raw_datasets/kutaykutlu_forest-fire/test_small/ -r\n",
    "!rm raw_datasets/kutaykutlu_forest-fire/test_big/ -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make things simpler, the datasets will be renamed: <br>\n",
    "alik05_forest-fire-dataset = dataset1 <br> <br>\n",
    "elmadafri_the-wildfire-dataset = dataset2 <br> <br>\n",
    "kutaykutlu_forest-fire = dataset3 <br> <br>\n",
    "mohnishsaiprasad_forest-fire-images = dataset4 <br> <br>\n",
    "phylake1337_fire-dataset = dataset5 <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path,folders,labels,resize=False):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    for folder,label in zip(folders,labels):\n",
    "        try:\n",
    "            for f in os.scandir(dataset_path+folder):\n",
    "                if f.is_file() and f.name.endswith((\".jpg\", \".png\")):\n",
    "                    img = Image.open(f.path)\n",
    "                    if resize:\n",
    "                        img = img.resize((256,256))\n",
    "                    img_array = np.array(img)\n",
    "                    img_array = img_array / 255.0\n",
    "                    dataset_x.append(img_array)\n",
    "                    dataset_y.append(label)\n",
    "        except:\n",
    "            break                \n",
    "    return dataset_x,dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_path = \"raw_datasets/alik05_forest-fire-dataset/Forest Fire Dataset/\"\n",
    "dataset2_path = \"raw_datasets/elmadafri_the-wildfire-dataset/the_wildfire_dataset_2n_version/\"\n",
    "dataset3_path = \"raw_datasets/kutaykutlu_forest-fire/\"\n",
    "dataset4_path = \"raw_datasets/mohnishsaiprasad_forest-fire-images/Data/\"\n",
    "dataset5_path = \"raw_datasets/phylake1337_fire-dataset/fire_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 1900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1_X, dataset1_Y = load_data(dataset1_path,[\"Training/fire\",\"Training/nofire\"],[1,0])\n",
    "\n",
    "for f in os.scandir(dataset1_path+\"Testing\"):\n",
    "    if f.is_file() and f.name.endswith((\".jpg\", \".png\")):\n",
    "        img = Image.open(f.path)\n",
    "        img = img.resize((256,256))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        dataset1_X.append(img_array)\n",
    "        dataset1_Y.append(0 if f.name.split(\"_\")[0] == \"nofire\" else 1)\n",
    "        \n",
    "len(dataset1_X),len(dataset1_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset2_X, dataset2_Y = load_data(dataset2_path,[\"test/fire\",\"test/nofire\",\"train/fire\",\"train/nofire\",\"val/fire\",\"val/nofire\"],[1,0,1,0,1,0],True)\\n\\nlen(dataset2_X),len(dataset2_Y)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dataset2_X, dataset2_Y = load_data(dataset2_path,[\"test/fire\",\"test/nofire\",\"train/fire\",\"train/nofire\",\"val/fire\",\"val/nofire\"],[1,0,1,0,1,0],True)\n",
    "\n",
    "len(dataset2_X),len(dataset2_Y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102, 1102)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3_X, dataset3_Y = load_data(dataset3_path,[\"train_fire\"],[1])\n",
    "\n",
    "len(dataset3_X),len(dataset3_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1628, 1628)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4_X, dataset4_Y = load_data(dataset4_path,[\"Test_Data/Fire\",\"Test_Data/Non_Fire\",\"Train_Data/Fire\",\"Train_Data/Non_Fire\"],[1,0,1,0])\n",
    "\n",
    "len(dataset4_X),len(dataset4_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset5_X, dataset5_Y = load_data(dataset5_path,[\"fire_images\",\"non_fire_images\"],[1,0])\n",
    "\n",
    "len(dataset5_X),len(dataset5_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset1_X = np.array(dataset1_X)\n",
    "dataset1_Y = np.array(dataset1_Y)\n",
    "dataset3_X = np.array(dataset3_X)\n",
    "dataset3_Y = np.array(dataset3_Y)\n",
    "dataset4_X = np.array(dataset4_X)\n",
    "dataset4_Y = np.array(dataset4_Y)\n",
    "dataset5_X = np.array(dataset5_X)\n",
    "dataset5_Y = np.array(dataset5_Y)\n",
    "\n",
    "X_train_dataset1,X_test_dataset1,Y_train_dataset1,Y_test_dataset1 = train_test_split(dataset1_X,dataset1_Y,test_size=0.16)\n",
    "X_train_dataset1,X_test_dataset1,Y_val_dataset1,Y_val_dataset1 = train_test_split(X_train_dataset1,Y_train_dataset1,test_size=0.19)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "second_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
